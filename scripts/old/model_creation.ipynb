{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DIzBRsb8g7l",
        "outputId": "f02221d8-4456-4190-918d-b1ea5f9f9660"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statistics  as stat\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import requests\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import pickle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier, RidgeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve, auc\n",
        "import itertools\n",
        "import ast\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "#from scikeras.wrappers import KerasRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tqdm import tqdm\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tgrTRBK9oVx"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv(path,sep=\",\")\n",
        "#print(df.dtypes.value_counts())\n",
        "prefixes = ['genre_','cast_','ts_','lang_','dir_','prod_','coll_']\n",
        "for p in prefixes:\n",
        "    n = sum(1 for c in df.columns if c.startswith(p))\n",
        "#    print(f\"{p:<8} → {n} columns\")\n",
        "#print(f\"Total columns: {df.shape[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "5kL0U6ti-Cg-",
        "outputId": "26b188a2-fc0f-41ce-9c3a-9ef6e6f31743"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# 1) Identify your dummy blocks\n",
        "cast_cols   = [c for c in df.columns if c.startswith(\"cast_\")]\n",
        "#kw_cols     = [c for c in df.columns if c.startswith(\"kw_\")]\n",
        "genre_cols  = [c for c in df.columns if c.startswith(\"genre_\")]\n",
        "lang_cols=[c for c in df.columns if c.startswith(\"lang_\")]\n",
        "dir_cols=[c for c in df.columns if c.startswith(\"dir_\")]\n",
        "prod_cols=[c for c in df.columns if c.startswith(\"prod_\")]\n",
        "coll_cols=[c for c in df.columns if c.startswith(\"coll_\")]\n",
        "\n",
        "# 2) Helper to plot cumulative variance\n",
        "def plot_cumvar(block_cols, title):\n",
        "    X = df[block_cols]\n",
        "    svd = TruncatedSVD(n_components=len(block_cols)-1, random_state=42)\n",
        "    svd.fit(X)\n",
        "    cumvar = svd.explained_variance_ratio_.cumsum()\n",
        "    plt.figure()\n",
        "    plt.plot(range(1, len(cumvar)+1), cumvar)\n",
        "    plt.xlabel(\"Number of components\")\n",
        "    plt.ylabel(\"Cumulative explained variance\")\n",
        "    plt.title(title)\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# 3) Plot for each block\n",
        "plot_cumvar(cast_cols,  \"Cast features\")\n",
        "#plot_cumvar(kw_cols,    \"Keyword features\")\n",
        "plot_cumvar(genre_cols, \"Genre features\")\n",
        "plot_cumvar(lang_cols, \"Language features\")\n",
        "plot_cumvar(dir_cols, \"director features\")\n",
        "plot_cumvar(prod_cols, \"production features\")\n",
        "plot_cumvar(coll_cols,\"collection\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm0tflca_bOp"
      },
      "source": [
        "| Feature block            | # original cols | \\~90% var @     | \\~95% var @     | Recommendation |\n",
        "| ------------------------ | --------------- | --------------- | --------------- | -------------- |\n",
        "| **Cast** (31 cols)       | 31              | \\~15 components | \\~22 components | **20**         |\n",
        "| **Keywords** (41 cols)   | 41              | \\~15 components | \\~30 components | **25**         |\n",
        "| **Genres** (11 cols)     | 11              | \\~5  components | \\~9  components | **6**          |\n",
        "| **Languages** (11 cols)  | 11              | \\~3  components | \\~6  components | **4–5**        |\n",
        "| **Directors** (11 cols)  | 11              | \\~4  components | \\~10 components | **5**          |\n",
        "| **Production** (11 cols) | 11              | \\~4  components | \\~10 components | **5**          |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSGJGC6ojwH8",
        "outputId": "6da961a0-fe17-496b-b074-8216707dc73c"
      },
      "outputs": [],
      "source": [
        "df=df.drop([\"title\",\"month\",\"id\",\"belongs_to_collection\",\"in_collection\",\"weekday\"],axis=1)\n",
        "print(df.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "Fw7CRbfF_OIG",
        "outputId": "de2cdf25-b85f-4127-c330-edca90ee2772"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "import numpy as np\n",
        "\n",
        "# 2) Apply TruncatedSVD with the chosen n_components\n",
        "#which dummy columns to reduce, e.g. cast_cols is a list of all \"cast_*\" columns and how many SVD components to keep for that block\n",
        "svd_params = {\n",
        "    'cast'  : (cast_cols,  30),\n",
        "    #'kw'    : (kw_cols,    30),\n",
        "    'genre' : (genre_cols,  10),\n",
        "    'lang'  : (lang_cols,   6),\n",
        "    'dir'   : (dir_cols,    10),\n",
        "    'prod'  : (prod_cols,   8)\n",
        "    #'coll' :(coll_cols, 3)\n",
        "}\n",
        "\n",
        "#Loop over each block\n",
        "\n",
        "for name, (cols, n_comp) in svd_params.items():\n",
        "    svd = TruncatedSVD(n_components=n_comp, random_state=42)\n",
        "    mat = svd.fit_transform(df[cols])\n",
        "    for i in range(n_comp):\n",
        "        df[f\"{name}_svd_{i}\"] = mat[:, i]\n",
        "    # drop the original dummies\n",
        "    df.drop(columns=cols, inplace=True)\n",
        "\n",
        "# 3) Ready for modeling\n",
        "#features: a list of all column names except the identifiers (title, id) and the target (total)\n",
        "features = [c for c in df.columns if c not in ['title','id','total']]\n",
        "#X: your final feature matrix, shape (n_samples, n_final_features)\n",
        "X = df[features].values\n",
        "#y: the target vector of ticket counts\n",
        "y = df['total'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oA36Ez9_Amuv"
      },
      "source": [
        "# Explaination\n",
        "\n",
        "1. Instantiate a TruncatedSVD with your chosen n_comp.\n",
        "\n",
        "2. Fit & transform only the sub-matrix df[cols] → mat is now (n_samples × n_comp).\n",
        "\n",
        "3. Write back each of the n_comp SVD columns into your DataFrame, named \"{name}_svd_0\", \"{name}_svd_1\", …\n",
        "\n",
        "4. Drop the original high-dimensional dummy columns (cols), since their information is now captured by the dense SVD components.\n",
        "\n",
        "By the end of this loop, you’ve replaced:\n",
        "*   31 cast dummies ➔ 20 cast_svd_* features\n",
        "*   41 keyword dummies ➔ 25 kw_svd_* features\n",
        "*   11 genre dummies ➔ 6 genre_svd_* features\n",
        "*   …and so on for the other blocks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M7CtOieQBQmr",
        "outputId": "00782db2-381f-4172-faad-377187fc744b"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 0) Ensure 'total' is numeric and drop any rows where it's NaN\n",
        "df['total'] = pd.to_numeric(df['total'], errors='coerce')\n",
        "df = df.dropna(subset=['total']).reset_index(drop=True)\n",
        "\n",
        "# 1) Select only numeric feature columns (auto‐drops any object/dict columns)\n",
        "numeric_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
        "numeric_cols.remove('total')  # exclude the target\n",
        "X = df[numeric_cols].values\n",
        "y = df['total'].values\n",
        "\n",
        "# 2) Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 3) Instantiate & fit Random Forest\n",
        "rf = RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=None,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# 4) Predict & evaluate\n",
        "y_pred = rf.predict(X_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "r2   = r2_score(y_test, y_pred)\n",
        "print(f\"Test RMSE: {rmse:.2f}\")\n",
        "print(f\"Test R²: {r2:.3f}\")\n",
        "\n",
        "# 5) Feature importances\n",
        "feat_imp = pd.Series(rf.feature_importances_, index=numeric_cols).sort_values(ascending=False)\n",
        "print(\"\\nTop 20 features by importance:\")\n",
        "print(feat_imp.head(20))\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "feat_imp.head(20).plot.barh()\n",
        "plt.gca().invert_yaxis()\n",
        "plt.title(\"Top 20 Feature Importances\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
